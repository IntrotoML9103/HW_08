{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QshK8s21WBrf"
   },
   "source": [
    "# HW08\n",
    "\n",
    "## Exercises to practice pandas, data analysis, regression and classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Hf8SXUwWOho"
   },
   "source": [
    "### Setup\n",
    "\n",
    "Run the following 2 cells to import all necessary libraries and helpers for this homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/src/data_utils.py\n",
    "!wget -q https://github.com/DM-GY-9103-2024F-H/9103-utils/raw/main/src/image_utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from os import listdir, path\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from data_utils import object_from_json_url\n",
    "from data_utils import StandardScaler\n",
    "from data_utils import LFWUtils\n",
    "from data_utils import LinearRegression, RandomForestClassifier, SVC\n",
    "from data_utils import classification_error, display_confusion_matrix, regression_error\n",
    "\n",
    "from image_utils import make_image, open_image\n",
    "\n",
    "from HW08_utils import CamUtils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "\n",
    "Let's load up the full [ANSUR](https://www.openlab.psu.edu/ansur2/) dataset that we looked at briefly in [Week 02](https://github.com/DM-GY-9103-2024F-H/WK02).\n",
    "\n",
    "This is the dataset that has anthropometric information about U.S. Army personnel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "ANSUR_FILE = \"https://raw.githubusercontent.com/DM-GY-9103-2024F-H/9103-utils/main/datasets/json/ansur.json\"\n",
    "ansur_data = object_from_json_url(ANSUR_FILE)\n",
    "\n",
    "# Look at first 2 records\n",
    "ansur_data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nested data\n",
    "\n",
    "This is that *nested* dataset from Week 02.\n",
    "\n",
    "# ü§î\n",
    "\n",
    "Let's load it into a `DataFrame` to see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read into DataFrame\n",
    "ansur_df = pd.DataFrame.from_records(ansur_data)\n",
    "ansur_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# üòìüôÑ\n",
    "\n",
    "That didn't work too well. We ended up with objects in our columns.\n",
    "\n",
    "Luckily, our `DataFrame` library has a function called [`json_normalize()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.json_normalize.html) that can help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read into DataFrame\n",
    "ansur_df = pd.json_normalize(ansur_data)\n",
    "ansur_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better. `DataFrames` are magic.\n",
    "\n",
    "#### Data Exploration\n",
    "\n",
    "Before we start creating models, let's do a little bit of data analysis and get a feeling for the shapes, distributions and relationships of our data.\n",
    "\n",
    "1. Print `min`, `max` and `average` values for all of the features.\n",
    "2. Print `covariance` tables for `age`, `ear.length` and `head.circumference`.\n",
    "3. Plot `age`, `ear.length` and `head.circumference` versus the $1$ *feature* that is most correlated to each of them.\n",
    "\n",
    "Don't forget to *encode* and *normalize* the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Work on Data Exploration here\n",
    "\n",
    "### Encode non-numerical features\n",
    "\n",
    "num_df = ansur_df.select_dtypes(include='number')\n",
    "\n",
    "## 1. Print min, max, avg\n",
    "print(\"\\n\\tmin:\", num_df.min())\n",
    "print(\"\\tmax:\\n\", num_df.max())\n",
    "print(\"\\tavg:\\n\", num_df.mean())\n",
    "\n",
    "\n",
    "### Normalize all data\n",
    "num_scaler = StandardScaler()\n",
    "num_df_scaled = num_scaler.fit_transform(num_df)\n",
    "\n",
    "## 2. Print Covariances\n",
    "display(num_df_scaled.cov())\n",
    "display(num_df_scaled.cov()[\"age\"])\n",
    "display(num_df_scaled.cov()[\"ear.length\"])\n",
    "display(num_df_scaled.cov()[\"head.circumference\"])\n",
    "\n",
    "## 3. Plot features most correlated to age, ear length and head circumference\n",
    "correlation = num_df_scaled.corr()\n",
    "\n",
    "for c in ['age', 'ear.length', 'head.circumference']:\n",
    "    corr_feat = correlation[c].drop(c).idxmax()\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(num_df_scaled[corr_feat], num_df_scaled[c], marker='o', alpha=0.3)\n",
    "    plt.xlabel(corr_feat)\n",
    "    plt.ylabel(c)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "Does anything stand out about these graphs? Or the correlations?<br>\n",
    "Are correlations symmetric? Does the feature most correlated to ear length also have ear length as its most correlated pair?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">EDIT THIS CELL WITH ANSWER</span>\n",
    "\n",
    "The only thing that really seems like has a correlation is the head circumference and height, the others do not really show a correlation. Since for age ear length is most correlated but for ear length age is not but instead weight is more correlated. Which does not show a strong correlation at all and indicates that they are not symmetric. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "\n",
    "Now, we want to create a regression model to predict `head.circumference` from the data.\n",
    "\n",
    "From our [Week 08](https://github.com/DM-GY-9103-2024F-H/WK08) notebook, we can create a regression model by following these steps:\n",
    "\n",
    "1. Load dataset (done! üéâ)\n",
    "2. Encode label features as numbers (done! ‚ö°Ô∏è)\n",
    "3. Normalize the data (done! üçæ)\n",
    "4. Separate the outcome variable and the input features\n",
    "5. Create a regression model using all features\n",
    "6. Run model on training data and measure error\n",
    "7. Plot predictions and interpret results\n",
    "8. Run model on test data, measure error, plot predictions, interpret results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Work on Regression Model here\n",
    "\n",
    "## Separate outcome variable and input features\n",
    "head_circumference = num_df_scaled[\"head.circumference\"]\n",
    "head_height = num_df_scaled[[\"head.height\"]]\n",
    "\n",
    "## Create a regression model\n",
    "feat_model = LinearRegression()\n",
    "\n",
    "feat_model.fit(head_height, head_circumference)\n",
    "\n",
    "## Measure error on training data\n",
    "predicted_feat = feat_model.predict(head_height)\n",
    "\n",
    "# Un-normalize the data\n",
    "predicted = num_scaler.inverse_transform(predicted_feat)\n",
    "\n",
    "## Plot predictions and interpret results\n",
    "plt.plot(num_df[\"head.height\"], num_df[\"head.circumference\"], marker='o', linestyle='', alpha=0.3)\n",
    "plt.plot(num_df[\"head.height\"], predicted, marker='', color='r')\n",
    "plt.title(\"head circumference VS head height\")\n",
    "plt.xlabel(\"head height\")\n",
    "plt.ylabel(\"head circumference\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Test Data\n",
    "ANSUR_TEST_FILE = \"https://raw.githubusercontent.com/DM-GY-9103-2024F-H/9103-utils/main/datasets/json/ansur-test.json\"\n",
    "ansur_test_data = object_from_json_url(ANSUR_TEST_FILE)\n",
    "ansur_test_df = pd.json_normalize(ansur_test_data)\n",
    "\n",
    "\n",
    "genders = [\"F\", \"M\"]\n",
    "ansur_encoder = OrdinalEncoder(categories=[genders])\n",
    "\n",
    "g_vals = ansur_encoder.fit_transform(ansur_test_df[[\"gender\"]].values)\n",
    "ansur_test_encoded_df = ansur_test_df.copy()\n",
    "ansur_test_encoded_df[\"gender\"] = g_vals\n",
    "\n",
    "ansur_scaler = StandardScaler()\n",
    "\n",
    "ansur_test_scaled_array = ansur_scaler.fit_transform(ansur_test_encoded_df) \n",
    "\n",
    "ansur_test_scaled_df = pd.DataFrame(ansur_test_scaled_array, columns=ansur_test_encoded_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "## Run model on test data\n",
    "test_model = LinearRegression()\n",
    "\n",
    "test_model.fit(head_height, head_circumference)\n",
    "\n",
    "head_height = ansur_test_scaled_df[[\"head.height\"]]\n",
    "\n",
    "## Measure error on test data\n",
    "predicted_t = feat_model.predict(head_height)\n",
    "\n",
    "# Un-normalize the data\n",
    "predicted_test = num_scaler.inverse_transform(predicted_t)\n",
    "\n",
    "print(\"pt:  \",len(predicted_test))\n",
    "print(\"at:  \",len(ansur_test_df[\"head.height\"]))\n",
    "\n",
    "## Plot predictions and interpret results\n",
    "plt.plot(ansur_test_df[\"head.height\"], ansur_test_df[\"head.circumference\"], marker='o', linestyle='', alpha=0.3)\n",
    "plt.plot(ansur_test_df[\"head.height\"], predicted_test, marker='', color='r')\n",
    "plt.title(\"head circumference VS head height\")\n",
    "plt.xlabel(\"head height\")\n",
    "plt.ylabel(\"head circumference\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "<span style=\"color:hotpink;\">\n",
    "How well does your classifier perform?<br>\n",
    "How could you improve it?<br>\n",
    "Are there ranges of circumferences that don't get predicted well?\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">It just shows the line of best fit, it doesn't really do a great job of predicting the correlation. We can add more parameters and classify the model better to have a better line that curves according to the existing data correlation. But maybe add other factors like gender and age can help with the classifcation.</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "The dataset we are going to use has images from $25$ different security cameras, and our task is to separate them by camera. Some of the cameras move, some of them don't, and there are more than $1000$ images, so there's no way we want to do this by hand.\n",
    "\n",
    "### Loading Data\n",
    "\n",
    "If we look at the images in `./data/images/0801-500/train/`, we'll notice that they are named and organized in a very particular way. They're all in the same directory and the first part of their filename specifies which camera they came from. Even though those `ids` are numbers, they're not sequential, so we'll use some helper functions to extract a unique `label` from their filenames.\n",
    "\n",
    "This is exactly what the `OrdinalEncoder` class does, but since we only have to encode this one column, we'll do it by hand while we read the files in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this creates a list of all the files in a given directory, that end in .jpg\n",
    "train_files = [f for f in listdir(\"./data/images/0801-500/train\") if f.endswith(\".jpg\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: check and see what is inside the list here\n",
    "\n",
    "train_files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll read the image pixels and extract their labels. `CamUtils.get_label()` is the helper function we'll use to \"encode\" and return a label id based on the filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_data = []\n",
    "label_data = []\n",
    "\n",
    "for fname in train_files:\n",
    "  label = CamUtils.get_label(fname)\n",
    "  img = open_image(path.join(\"./data/images/0801-500/train\", fname))\n",
    "  pixel_data.append(img.pixels)\n",
    "  label_data.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: check if labels got extracted correctly by looking at \n",
    "#       the first few items of the label list and the filename list\n",
    "\n",
    "print(\"pd: \",pixel_data[:5])\n",
    "print(\"ld: \",label_data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels and the filenames won't match exactly since labels start at $0$ and the filenames start at $01$ and skip some numbers.\n",
    "\n",
    "We can open some images from pixels, just to make sure we loaded them correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(make_image(pixel_data[0], width=256))\n",
    "display(make_image(pixel_data[10], width=256))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now might not be a bad time to peek into the `data/images/0801-500/` directories to see what's inside them and what the images look like.... and get to know the data..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataFrame it\n",
    "\n",
    "Let's put our raw pixel data into a `DataFrame`, and create a column for storing each image's label.\n",
    "\n",
    "(this next cell might take a while to run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(pixel_data)\n",
    "train_df[\"label\"] = label_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect our `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Files\n",
    "\n",
    "If that worked, repeat the process for the test files inside the `./data/images/0801-500/test/` directory.\n",
    "\n",
    "We can almost use the exact same steps as we did above to create a `DataFrame`, the only difference being that we don't have labels for these images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len:  1573\n",
      "data:  ['15709132.jpg', '12405239.jpg', '10894318.jpg', '15584424.jpg', '10656623.jpg']\n"
     ]
    }
   ],
   "source": [
    "# TODO: create a list of files in the test/ directory\n",
    "\n",
    "test_files = [f for f in listdir(\"./data/images/0801-500/test/\") if f.endswith(\".jpg\")]\n",
    "\n",
    "# TODO: check its length and content\n",
    "print(\"len: \",len(test_files))\n",
    "print(\"data: \",test_files[:5])\n",
    "\n",
    "test_pixel_data = []\n",
    "\n",
    "# TODO: loop over files and load their pixels into a list\n",
    "for fname in test_files:\n",
    "    img = open_image(path.join(\"./data/images/0801-500/test/\", fname))\n",
    "    test_pixel_data.append(img.pixels)\n",
    "\n",
    "# TODO: load into DataFrame (this might take 20 - 30 seconds)\n",
    "test_df = pd.DataFrame(test_pixel_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>65526</th>\n",
       "      <th>65527</th>\n",
       "      <th>65528</th>\n",
       "      <th>65529</th>\n",
       "      <th>65530</th>\n",
       "      <th>65531</th>\n",
       "      <th>65532</th>\n",
       "      <th>65533</th>\n",
       "      <th>65534</th>\n",
       "      <th>65535</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>101</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>99</td>\n",
       "      <td>98</td>\n",
       "      <td>98</td>\n",
       "      <td>105</td>\n",
       "      <td>104</td>\n",
       "      <td>...</td>\n",
       "      <td>172</td>\n",
       "      <td>185</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>182</td>\n",
       "      <td>185</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>185</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131</td>\n",
       "      <td>131</td>\n",
       "      <td>131</td>\n",
       "      <td>132</td>\n",
       "      <td>133</td>\n",
       "      <td>134</td>\n",
       "      <td>135</td>\n",
       "      <td>136</td>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>147</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>143</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>53</td>\n",
       "      <td>54</td>\n",
       "      <td>57</td>\n",
       "      <td>62</td>\n",
       "      <td>66</td>\n",
       "      <td>61</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>168</td>\n",
       "      <td>160</td>\n",
       "      <td>156</td>\n",
       "      <td>159</td>\n",
       "      <td>162</td>\n",
       "      <td>162</td>\n",
       "      <td>161</td>\n",
       "      <td>162</td>\n",
       "      <td>165</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141</td>\n",
       "      <td>172</td>\n",
       "      <td>202</td>\n",
       "      <td>198</td>\n",
       "      <td>221</td>\n",
       "      <td>231</td>\n",
       "      <td>232</td>\n",
       "      <td>219</td>\n",
       "      <td>187</td>\n",
       "      <td>148</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>29</td>\n",
       "      <td>22</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 65536 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3      4      5      6      7      8      9      ...  \\\n",
       "0    101    101    100    100    100     99     98     98    105    104  ...   \n",
       "1    131    131    131    132    133    134    135    136    135    135  ...   \n",
       "2     54     54     54     53     54     57     62     66     61     59  ...   \n",
       "3    141    172    202    198    221    231    232    219    187    148  ...   \n",
       "4      9     14     14     20     29     22     13     16     11     14  ...   \n",
       "\n",
       "   65526  65527  65528  65529  65530  65531  65532  65533  65534  65535  \n",
       "0    172    185    180    180    182    185    189    189    185    180  \n",
       "1    149    149    149    147    145    145    145    145    143    141  \n",
       "2    168    160    156    159    162    162    161    162    165    168  \n",
       "3     33     34     24     25     25     25     25     25     26     26  \n",
       "4      3      3      1      1      1      1      1      1      1      1  \n",
       "\n",
       "[5 rows x 65536 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like data!!\n",
    "\n",
    "We could train a `RandomForestClassifier` directly on this `DataFrame` and see what would happen, but my guess is that Python runs out of memory and crashes our tab/browser/computer...\n",
    "\n",
    "We'll use _projection_ to reduce the number of dimensions in our dataset. Projection is when we just drop some of the columns in our dataset. \n",
    "\n",
    "Which columns ? That's up to us.\n",
    "\n",
    "Let's first try using the first $N$ columns/features where $N$ is a number around $10$.\n",
    "\n",
    "This is how we get the first $N$ columns from a `DataFrame`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split input and output features\n",
    "NUM_FEATURES = 10\n",
    "chosen_columns = train_df.columns[:NUM_FEATURES]\n",
    "train_features = train_df[chosen_columns]\n",
    "\n",
    "out_features = train_df[\"label\"]\n",
    "\n",
    "# also separate test dataset features\n",
    "test_features = test_df[chosen_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our [Week 08](https://github.com/DM-GY-9103-2024F-H/WK08) notebook, we can create a classification model by following these steps:\n",
    "\n",
    "1. Load dataset (done! üéâ)\n",
    "2. Encode label features as numbers (not needed! done! ‚ö°Ô∏è)\n",
    "3. Normalize the data (not needed! done! üçæ)\n",
    "4. Separate the outcome variable and the input features (done! ‚òÄÔ∏è)\n",
    "5. Create a model using chosen features\n",
    "6. Run model on training data and measure error*\n",
    "7. Run model on test data, measure error*, plot predictions, interpret results\n",
    "\n",
    "*: we can use the same `regression_error()` function we used above to measure the error of our classifier model, but this could lead to $2$ issues. First, we don't have labels for the images in the test dataset, and second, the regression error reported might be higher than it actually is because an image with label $0$ that gets mislabeled as $5$ will count as being more wrong than if it was mislabeled $2$. And we don't want that. We just want to get the percentage of classifications that our model gets correctly.\n",
    "\n",
    "To simplify calculating the classification accuracy we can use the `CamUtils.classification_accuracy()` function. This function takes $2$ parameters, a list of files and a list of predictions. It will work with the test and train datasets and will calculate a more accurate accuracy value than the one returned by `regression_error()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: create a brand new classifier\n",
    "# TODO: fit the model\n",
    "# TODO: run predictions\n",
    "# TODO: measure classification accuracy\n",
    "CamUtils.classification_accuracy(train_files, train_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That should look promising. Let's run this on our test dataset.\n",
    "\n",
    "Remember we already separated the test data features into a variable called `test_features` above.\n",
    "\n",
    "Now we just have to run the prediction and measure accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "outputs": [],
   "source": [
    "# TODO: run predictions on test data\n",
    "# TODO: measure classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "Using just the first $10$ pixels of the image the classifier is able to label most of the images correctly.\n",
    "\n",
    "<span style=\"color:hotpink\">\n",
    "How can we improve this classifier? How does the number of features affect the classification accuracy of the test data<br>\n",
    "How does the choice of pixels affect the accuracy?<br><br>\n",
    "Experiment with some of these parameters and explain your findings below.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "work_cell"
    ]
   },
   "source": [
    "<span style=\"color:hotpink;\">EDIT THIS CELL WITH ANSWER</span>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPxe2qYxIG7EblrvD1C4Pmv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
